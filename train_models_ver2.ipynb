{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6bf7dde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "from o3d_tools.visualize import PointCloudProject\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "#import torch_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29ee577",
   "metadata": {},
   "outputs": [],
   "source": [
    "project1 = PointCloudProject(project='Project1') ; project2 = PointCloudProject(project='Project2')\n",
    "project3 = PointCloudProject(project='Project3') ; project4 = PointCloudProject(project='Project4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ce948d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_data():\n",
    "\n",
    "    objs1 = project1.objects_df\n",
    "\n",
    "    print(f\"Types of objects in Project 1: {list(objs1.keys())}\")\n",
    "    pipes1 = objs1[\"Pipe\"]\n",
    "    scbs1 = objs1[\"Structural_ColumnBeam\"]\n",
    "    sibs1 = objs1[\"Structural_IBeam\"]\n",
    "    hvducts = objs1[\"HVAC_Duct\"]\n",
    "\n",
    "    objs2 = project2.objects_df\n",
    "\n",
    "    print(f\"Types of objects in Project 2: {list(objs2.keys())}\")\n",
    "    pipes2 = objs2[\"Pipe\"]\n",
    "    scbs2 = objs2[\"Structural_ColumnBeam\"]\n",
    "    sibs2 = objs2[\"Structural_IBeam\"]\n",
    "\n",
    "    objs3 = project3.objects_df\n",
    "\n",
    "    print(f\"Types of objects in Project 3: {list(objs3.keys())}\")\n",
    "    scbs3 = objs3[\"Structural_ColumnBeam\"]\n",
    "\n",
    "    objs4 = project4.objects_df\n",
    "\n",
    "    print(f\"Types of objects in Project 4: {list(objs4.keys())}\")\n",
    "    sibs4 = objs4[\"Structural_IBeam\"]\n",
    "\n",
    "\n",
    "    boxes1 = pd.concat([scbs1, hvducts, pipes1, sibs1])\n",
    "    boxes2 = pd.concat([scbs2, pipes2, sibs2])\n",
    "    boxes3 = scbs3\n",
    "    boxes4 = sibs4\n",
    "\n",
    "    boxes = [boxes1, boxes2, boxes3, boxes4]\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        boxes[i].rename(columns={\" Label\": \"label\", \" BB.Min.X \" : \"min_x\", \" BB.Min.Y \" : \"min_y\", \" BB.Min.Z \" : \"min_z\",\n",
    "                             \" BB.Max.X \" : \"max_x\", \" BB.Max.Y \" : \"max_y\", \" BB.Max.Z\" : \"max_z\"}, inplace=True)\n",
    "\n",
    "    box_data = pd.concat(boxes)\n",
    "\n",
    "    ids_to_points = {}\n",
    "\n",
    "    projects = [project1, project2, project3, project4]\n",
    "\n",
    "    for proj_id, box in enumerate(boxes):\n",
    "\n",
    "        for i, ID in enumerate(box[\"ID\"]):\n",
    "\n",
    "            proj = projects[proj_id]\n",
    "\n",
    "            # .pcd.crop() method expects this bounding box object, create it from the raw min max values\n",
    "            bb = o3d.geometry.AxisAlignedBoundingBox((box[[\"min_x\", \"min_y\", \"min_z\"]].iloc[i]).to_numpy(), \n",
    "                                        (box[[\"max_x\", \"max_y\", \"max_z\"]].iloc[i]).to_numpy())\n",
    "\n",
    "            points_of_id = proj.pcd.crop(bb)\n",
    "\n",
    "            # convert the pointcloud object into a numpy array\n",
    "            # join coordinates and color data into a single 6d nparray for each point\n",
    "\n",
    "            points_coords = np.asarray(points_of_id.points)\n",
    "\n",
    "            tmp = np.asarray(points_of_id.colors)[:,0]\n",
    "\n",
    "            points_colors = (np.asarray(points_of_id.colors)[:,0]).reshape(-1,1)\n",
    "\n",
    "            points_arr = np.concatenate((points_coords, points_colors), axis = 1)\n",
    "\n",
    "            ids_to_points[ID] = points_arr\n",
    "\n",
    "    def sample_point_cloud(points, num_points):\n",
    "\n",
    "        if points.shape[0] > num_points:\n",
    "\n",
    "            # Downsample if the point cloud has more points than needed\n",
    "            idx = np.random.choice(points.shape[0], num_points, replace=False)\n",
    "            return points[idx, :]\n",
    "\n",
    "        elif points.shape[0] < num_points:\n",
    "            # Upsample by repeating random points if the point cloud has fewer points than needed\n",
    "            idx = np.random.choice(points.shape[0], num_points - points.shape[0], replace=True)\n",
    "            return np.concatenate([points, points[idx, :]], axis=0)\n",
    "\n",
    "        else:\n",
    "            # Return the point cloud as is if it already has the correct number of points\n",
    "            return points\n",
    "\n",
    "    fixed_num_points = 2048  # The fixed number of points for all point clouds\n",
    "\n",
    "    point_clouds_resampled = {}\n",
    "\n",
    "    for obj_id in ids_to_points.keys():\n",
    "\n",
    "        point_cloud = ids_to_points[obj_id]\n",
    "        resampled_points = sample_point_cloud(point_cloud, fixed_num_points)\n",
    "        point_clouds_resampled[obj_id] = resampled_points\n",
    "        \n",
    "    def extract_bounding_box_features(min_x, max_x, min_y, max_y, min_z, max_z):\n",
    "    \n",
    "        centroid = [(min_x + max_x) / 2, (min_y + max_y) / 2, (min_z + max_z) / 2]\n",
    "        size = [max_x - min_x, max_y - min_y, max_z - min_z]\n",
    "        volume = size[0] * size[1] * size[2]\n",
    "        \n",
    "        return np.array(centroid + size + [volume])\n",
    "    \n",
    "    data = []\n",
    "    for i in range(box_data.shape[0]):\n",
    "\n",
    "        box = box_data.iloc[i]\n",
    "        features = extract_bounding_box_features(box[\"min_x\"], box[\"max_x\"], box[\"min_y\"],\n",
    "                                                 box[\"max_y\"], box[\"min_z\"], box[\"max_z\"])\n",
    "\n",
    "        data.append(features)\n",
    "\n",
    "    feature_df = pd.DataFrame(data, columns=[\"cx\", \"cy\", \"cz\", \"sx\", \"sy\", \"sz\", \"vol\"])\n",
    "    \n",
    "    box_data = box_data.reset_index(drop=True)\n",
    "    \n",
    "    new_box_data = pd.concat([box_data, feature_df], axis=1)\n",
    "    \n",
    "    return point_clouds_resampled, new_box_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11f78bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of objects in Project 1: ['Structural_ColumnBeam', 'HVAC_Duct', 'Pipe', 'Structural_IBeam']\n",
      "Types of objects in Project 2: ['Structural_ColumnBeam', 'Pipe', 'Structural_IBeam']\n",
      "Types of objects in Project 3: ['Structural_ColumnBeam']\n",
      "Types of objects in Project 4: ['Structural_IBeam']\n"
     ]
    }
   ],
   "source": [
    "points_dict, box_data = read_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32605e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = box_data[\"label\"]\n",
    "X = box_data[[\"ID\", \"min_x\", \"min_y\", \"min_z\", \"max_x\", \"max_y\", \"max_z\", \"cx\", \"cy\", \"cz\", \"sx\", \"sy\", \"sz\", \"vol\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cfcbf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6481373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(270, 14)\n",
      "(90, 14)\n",
      "(90, 14)\n",
      "(270,)\n",
      "(90,)\n",
      "(90,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a2d6bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_point_cloud_data(points, labels):\n",
    "    \n",
    "    # Points is of shape [2048, 3] (x, y, z coordinates)\n",
    "    # Grayscale intensity is of shape [2048, 1] \n",
    "    # Labels are the classification targets for each bounding box\n",
    "\n",
    "    x = torch.tensor(points, dtype=torch.float)  # Point cloud coordinates\n",
    "    print(x)\n",
    "    print(x.shape)\n",
    "\n",
    "    # Create an edge index using k-nearest neighbors (or some method to define neighbors)\n",
    "    edge_index = T.KNNGraph(k=16)(Data(pos=x)).edge_index  # Edge index for the graph\n",
    "\n",
    "    # Create the Data object\n",
    "    data = Data(x=x, edge_index=edge_index, y=torch.tensor(labels, dtype=torch.long))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e853d848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-cluster in c:\\users\\kelis\\anaconda3\\lib\\site-packages (1.6.3+pt21cu121)\n",
      "Requirement already satisfied: scipy in c:\\users\\kelis\\anaconda3\\lib\\site-packages (from torch-cluster) (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\kelis\\anaconda3\\lib\\site-packages (from scipy->torch-cluster) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f64b629b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.2062e+02,  3.3525e+02,  8.5944e+01,  4.4141e-01],\n",
      "        [-2.2178e+02,  3.3635e+02,  9.7627e+01,  1.5625e-02],\n",
      "        [-2.2102e+02,  3.3530e+02,  9.5444e+01,  2.8125e-01],\n",
      "        ...,\n",
      "        [-2.2069e+02,  3.3543e+02,  9.3237e+01,  2.3047e-01],\n",
      "        [-2.2155e+02,  3.3607e+02,  8.5803e+01,  3.4766e-01],\n",
      "        [-2.1956e+02,  3.3600e+02,  8.5739e+01,  3.2422e-01]])\n",
      "torch.Size([2048, 4])\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "'knn_graph' requires 'torch-cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m graph_dict \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj_id \u001b[38;5;129;01min\u001b[39;00m points_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m----> 5\u001b[0m     graph_dict[obj_id] \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_point_cloud_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobj_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbox_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mID\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobj_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[35], line 12\u001b[0m, in \u001b[0;36mcreate_point_cloud_data\u001b[1;34m(points, labels)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Create an edge index using k-nearest neighbors (or some method to define neighbors)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKNNGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39medge_index  \u001b[38;5;66;03m# Edge index for the graph\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Create the Data object\u001b[39;00m\n\u001b[0;32m     15\u001b[0m data \u001b[38;5;241m=\u001b[39m Data(x\u001b[38;5;241m=\u001b[39mx, edge_index\u001b[38;5;241m=\u001b[39medge_index, y\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor(labels, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch_geometric\\transforms\\base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch_geometric\\transforms\\knn_graph.py:51\u001b[0m, in \u001b[0;36mKNNGraph.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Data:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m data\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_geometric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcosine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforce_undirected:\n\u001b[0;32m     62\u001b[0m         edge_index \u001b[38;5;241m=\u001b[39m to_undirected(edge_index, num_nodes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mnum_nodes)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch_geometric\\nn\\pool\\__init__.py:171\u001b[0m, in \u001b[0;36mknn_graph\u001b[1;34m(x, k, batch, loop, flow, cosine, num_workers, batch_size)\u001b[0m\n\u001b[0;32m    168\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch_geometric\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mWITH_TORCH_CLUSTER_BATCH_SIZE:\n\u001b[1;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_cluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn_graph\u001b[49m(x, k, batch, loop, flow, cosine,\n\u001b[0;32m    172\u001b[0m                                    num_workers)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch_cluster\u001b[38;5;241m.\u001b[39mknn_graph(x, k, batch, loop, flow, cosine,\n\u001b[0;32m    174\u001b[0m                                num_workers, batch_size)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch_geometric\\typing.py:104\u001b[0m, in \u001b[0;36mTorchCluster.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m requires \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch-cluster\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: 'knn_graph' requires 'torch-cluster'"
     ]
    }
   ],
   "source": [
    "graph_dict = []\n",
    "\n",
    "for obj_id in points_dict.keys():\n",
    "    \n",
    "    graph_dict[obj_id] = create_point_cloud_data(points_dict[obj_id], box_data[box_data[\"ID\"] == obj_id])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
