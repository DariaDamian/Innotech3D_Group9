{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a994e5e9-ee88-40d3-beb9-dfb6e604a48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "from o3d_tools.visualize import PointCloudProject\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Dataset, DataLoader\n",
    "import torch_cluster\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import PointTransformerConv, global_max_pool, knn_graph\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8438fd61-4dc5-435a-9723-1be23c52ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "project1 = PointCloudProject(project='Project1') ; project2 = PointCloudProject(project='Project2')\n",
    "project3 = PointCloudProject(project='Project3') ; project4 = PointCloudProject(project='Project4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54876f4a-2330-467e-be21-1efa227bd859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of objects in Project 1: ['Structural_ColumnBeam', 'HVAC_Duct', 'Pipe', 'Structural_IBeam']\n",
      "Types of objects in Project 2: ['Structural_ColumnBeam', 'Pipe', 'Structural_IBeam']\n",
      "Types of objects in Project 3: ['Structural_ColumnBeam']\n",
      "Types of objects in Project 4: ['Structural_IBeam']\n",
      "Initial preprocessing done\n",
      "Train val test split done\n",
      "Label encoding done\n"
     ]
    }
   ],
   "source": [
    "def read_and_preprocess_data():\n",
    "\n",
    "    objs1 = project1.objects_df\n",
    "\n",
    "    print(f\"Types of objects in Project 1: {list(objs1.keys())}\")\n",
    "    pipes1 = objs1[\"Pipe\"]\n",
    "    scbs1 = objs1[\"Structural_ColumnBeam\"]\n",
    "    sibs1 = objs1[\"Structural_IBeam\"]\n",
    "    hvducts = objs1[\"HVAC_Duct\"]\n",
    "\n",
    "    objs2 = project2.objects_df\n",
    "\n",
    "    print(f\"Types of objects in Project 2: {list(objs2.keys())}\")\n",
    "    pipes2 = objs2[\"Pipe\"]\n",
    "    scbs2 = objs2[\"Structural_ColumnBeam\"]\n",
    "    sibs2 = objs2[\"Structural_IBeam\"]\n",
    "\n",
    "    objs3 = project3.objects_df\n",
    "\n",
    "    print(f\"Types of objects in Project 3: {list(objs3.keys())}\")\n",
    "    scbs3 = objs3[\"Structural_ColumnBeam\"]\n",
    "\n",
    "    objs4 = project4.objects_df\n",
    "\n",
    "    print(f\"Types of objects in Project 4: {list(objs4.keys())}\")\n",
    "    sibs4 = objs4[\"Structural_IBeam\"]\n",
    "\n",
    "\n",
    "    boxes1 = pd.concat([scbs1, hvducts, pipes1, sibs1])\n",
    "    boxes2 = pd.concat([scbs2, pipes2, sibs2])\n",
    "    boxes3 = scbs3\n",
    "    boxes4 = sibs4\n",
    "\n",
    "    boxes = [boxes1, boxes2, boxes3, boxes4]\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        boxes[i].rename(columns={\" Label\": \"label\", \" BB.Min.X \" : \"min_x\", \" BB.Min.Y \" : \"min_y\", \" BB.Min.Z \" : \"min_z\",\n",
    "                             \" BB.Max.X \" : \"max_x\", \" BB.Max.Y \" : \"max_y\", \" BB.Max.Z\" : \"max_z\"}, inplace=True)\n",
    "\n",
    "    box_data = pd.concat(boxes)\n",
    "\n",
    "    ids_to_points = {}\n",
    "\n",
    "    projects = [project1, project2, project3, project4]\n",
    "\n",
    "    for proj_id, box in enumerate(boxes):\n",
    "\n",
    "        for i, ID in enumerate(box[\"ID\"]):\n",
    "\n",
    "            proj = projects[proj_id]\n",
    "\n",
    "            # .pcd.crop() method expects this bounding box object, create it from the raw min max values\n",
    "            bb = o3d.geometry.AxisAlignedBoundingBox((box[[\"min_x\", \"min_y\", \"min_z\"]].iloc[i]).to_numpy(), \n",
    "                                        (box[[\"max_x\", \"max_y\", \"max_z\"]].iloc[i]).to_numpy())\n",
    "\n",
    "            points_of_id = proj.pcd.crop(bb)\n",
    "\n",
    "            # convert the pointcloud object into a numpy array\n",
    "            # join coordinates and color data into a single 6d nparray for each point\n",
    "\n",
    "            points_coords = np.asarray(points_of_id.points)\n",
    "\n",
    "            tmp = np.asarray(points_of_id.colors)[:,0]\n",
    "\n",
    "            points_colors = (np.asarray(points_of_id.colors)[:,0]).reshape(-1,1)\n",
    "\n",
    "            points_arr = np.concatenate((points_coords, points_colors), axis = 1)\n",
    "\n",
    "            ids_to_points[ID] = points_arr\n",
    "\n",
    "    def sample_point_cloud(points, num_points):\n",
    "\n",
    "        if points.shape[0] > num_points:\n",
    "\n",
    "            # Downsample if the point cloud has more points than needed\n",
    "            idx = np.random.choice(points.shape[0], num_points, replace=False)\n",
    "            return points[idx, :]\n",
    "\n",
    "        elif points.shape[0] < num_points:\n",
    "            # Upsample by repeating random points if the point cloud has fewer points than needed\n",
    "            idx = np.random.choice(points.shape[0], num_points - points.shape[0], replace=True)\n",
    "            return np.concatenate([points, points[idx, :]], axis=0)\n",
    "\n",
    "        else:\n",
    "            # Return the point cloud as is if it already has the correct number of points\n",
    "            return points\n",
    "\n",
    "    fixed_num_points = 2048  # The fixed number of points for all point clouds\n",
    "\n",
    "    point_clouds_resampled = {}\n",
    "\n",
    "    for obj_id in ids_to_points.keys():\n",
    "\n",
    "        point_cloud = ids_to_points[obj_id]\n",
    "        resampled_points = sample_point_cloud(point_cloud, fixed_num_points)\n",
    "        point_clouds_resampled[obj_id] = resampled_points\n",
    "        \n",
    "    def extract_bounding_box_features(min_x, max_x, min_y, max_y, min_z, max_z):\n",
    "    \n",
    "        centroid = [(min_x + max_x) / 2, (min_y + max_y) / 2, (min_z + max_z) / 2]\n",
    "        size = [max_x - min_x, max_y - min_y, max_z - min_z]\n",
    "        volume = size[0] * size[1] * size[2]\n",
    "        \n",
    "        return np.array(centroid + size + [volume])\n",
    "    \n",
    "    data = []\n",
    "    for i in range(box_data.shape[0]):\n",
    "\n",
    "        box = box_data.iloc[i]\n",
    "        features = extract_bounding_box_features(box[\"min_x\"], box[\"max_x\"], box[\"min_y\"],\n",
    "                                                 box[\"max_y\"], box[\"min_z\"], box[\"max_z\"])\n",
    "\n",
    "        data.append(features)\n",
    "\n",
    "    feature_df = pd.DataFrame(data, columns=[\"cx\", \"cy\", \"cz\", \"sx\", \"sy\", \"sz\", \"vol\"])\n",
    "    \n",
    "    box_data = box_data.reset_index(drop=True)\n",
    "    \n",
    "    new_box_data = pd.concat([box_data, feature_df], axis=1)\n",
    "    \n",
    "    return point_clouds_resampled, new_box_data\n",
    "\n",
    "points_dict, box_data = read_and_preprocess_data()\n",
    "\n",
    "print(\"Initial preprocessing done\")\n",
    "\n",
    "y = box_data[\"label\"]\n",
    "X = box_data[[\"ID\", \"min_x\", \"min_y\", \"min_z\", \"max_x\", \"max_y\", \"max_z\", \"cx\", \"cy\", \"cz\", \"sx\", \"sy\", \"sz\", \"vol\"]]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "print(\"Train val test split done\")\n",
    "\n",
    "label_mapping = {\n",
    "    'Structural_ColumnBeam': 0,\n",
    "    'HVAC_Duct': 1,\n",
    "    'Pipe': 2,\n",
    "    'Structural_IBeam': 3\n",
    "}\n",
    "\n",
    "labels_enc = []\n",
    "for row in box_data[\"label\"]:\n",
    "\n",
    "    labels_enc.append(label_mapping[row])\n",
    "\n",
    "box_data[\"label_enc\"] = labels_enc\n",
    "\n",
    "print(\"Label encoding done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad770641-cb1c-48e6-86cc-76b03a28c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData(Data):\n",
    "    def __cat_dim__(self, key, value, *args, **kwargs):\n",
    "        if key == 'bbox_features':\n",
    "            return None  # Indicates that bbox_features is a graph-level attribute\n",
    "        else:\n",
    "            return super(CustomData, self).__cat_dim__(key, value, *args, **kwargs)\n",
    "\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'bbox_features':\n",
    "            return 0  # No increment needed for graph-level attributes\n",
    "        else:\n",
    "            return super(CustomData, self).__inc__(key, value, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07754132-bd40-4381-be3a-745bce2e7a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_point_cloud_data(points, bounding_box_features, labels):\n",
    "\n",
    "    x = torch.tensor(points[:,3:], dtype=torch.float)  # Pointcolors\n",
    "    pos = torch.tensor(points[:, :3], dtype=torch.float) # Point coords\n",
    "\n",
    "    bounding_box_features = torch.tensor(bounding_box_features, dtype=torch.float)\n",
    "\n",
    "    # Create the Data object\n",
    "    data = CustomData(x=x, pos=pos, bbox_features=bounding_box_features, y=torch.tensor(labels, dtype=torch.long))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03edd601-410e-458e-9416-381e0965a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "features_list = [\"cx\", \"cy\", \"cz\", \"sx\", \"sy\", \"sz\", \"vol\"]\n",
    "\n",
    "for obj_id in points_dict.keys():\n",
    "\n",
    "    curr_label = ((box_data[box_data[\"ID\"] == obj_id].iloc[:,15]).to_numpy()).reshape(1)\n",
    "    curr_features = ((box_data[box_data[\"ID\"] == obj_id].loc[:,features_list]).to_numpy()).reshape(7)\n",
    "    \n",
    "    data_dict[obj_id] = create_point_cloud_data(points_dict[obj_id], curr_features, curr_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ce80f9-a8f7-4665-a106-61bf8be1153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_objs = {}\n",
    "val_data_objs = {}\n",
    "test_data_objs = {}\n",
    "\n",
    "for key in X_train[\"ID\"]:\n",
    "\n",
    "    train_data_objs[key] = data_dict[key]\n",
    "\n",
    "for key in X_val[\"ID\"]:\n",
    "\n",
    "    val_data_objs[key] = data_dict[key]\n",
    "\n",
    "for key in X_test[\"ID\"]:\n",
    "\n",
    "    test_data_objs[key] = data_dict[key]\n",
    "\n",
    "\n",
    "train_data_arr = []\n",
    "\n",
    "for key in train_data_objs.keys():\n",
    "\n",
    "    train_data_arr.append(train_data_objs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8fe57c2-3354-4586-a5c6-274ada249160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointTransformerModel(torch.nn.Module):\n",
    "    def __init__(self, num_classes=4, bbox_input_size=7):\n",
    "        super(PointTransformerModel, self).__init__()\n",
    "\n",
    "        # Point Transformer layers\n",
    "        self.conv1 = PointTransformerConv(in_channels=1, out_channels=10)\n",
    "        self.conv2 = PointTransformerConv(in_channels=10, out_channels=20)\n",
    "        self.conv3 = PointTransformerConv(in_channels=20, out_channels=30)\n",
    "\n",
    "        # Fully Connected Layers for Bounding Box Features\n",
    "        self.fc_bbox = torch.nn.Sequential(\n",
    "            torch.nn.Linear(bbox_input_size, 10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10, 20)\n",
    "        )\n",
    "\n",
    "        # Final Fully Connected Layers\n",
    "        self.fc_final = torch.nn.Sequential(\n",
    "            torch.nn.Linear(50, 10),\n",
    "            torch.nn.ReLU(),\n",
    "            #torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(10, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, pos, batch = data.x, data.pos, data.batch\n",
    "\n",
    "        edge_index = knn_graph(pos, k=5, batch=batch, loop=False)\n",
    "\n",
    "        # Point Transformer Convolutions\n",
    "        try:\n",
    "            x = F.relu(self.conv1(x, pos, edge_index))\n",
    "            print(f\"x after conv1 : {x.shape}\")\n",
    "            print(\"Conv1 done\")\n",
    "        except:\n",
    "            print(\"error at conv1\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            x = F.relu(self.conv2(x, pos, edge_index))\n",
    "            print(f\"x after conv2 : {x.shape}\")\n",
    "            print(\"Conv2 done\")\n",
    "        except:\n",
    "            print(\"error at conv2\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            x = F.relu(self.conv3(x, pos, edge_index))\n",
    "            print(f\"x after conv3 : {x.shape}\")\n",
    "            print(\"Conv3 done\")\n",
    "        except:\n",
    "            print(\"error at conv3\")\n",
    "            return\n",
    "\n",
    "        # Global Max Pooling\n",
    "        x = global_max_pool(x, batch)\n",
    "        print(f\"x after max pool : {x.shape}\")\n",
    "        print(\"Max Pool done\")\n",
    "        try:\n",
    "            # Process bounding box features\n",
    "            bbox_features = data.bbox_features\n",
    "            if bbox_features.dim() == 1:\n",
    "                bbox_features = bbox_features.unsqueeze(0)\n",
    "            bbox_out = self.fc_bbox(bbox_features)\n",
    "            print(\"Forward 1 done\")\n",
    "        except:\n",
    "            print(\"error at forward pass of bbox features\")\n",
    "            return\n",
    "\n",
    "        # Concatenate features\n",
    "        x = torch.cat([x, bbox_out], dim=1)\n",
    "        print(f\"x after concat : {x.shape}\")\n",
    "        print(\"Concatenate done\")\n",
    "\n",
    "        # Final classification layers\n",
    "        x = self.fc_final(x)\n",
    "        print(\"Classification done\")\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8eec305-c902-461c-834b-6c1e0dc19e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointTransformerModel(num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a53d56fc-9602-4311-8c13-75667e1d06e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.9/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "train_loader = DataLoader(train_data_arr, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81fad75f-d67a-4d80-89c3-151640eec7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_nan_inf(tensor, name):\n",
    "    if torch.isnan(tensor).any():\n",
    "        print(f\"{name} contains NaN values\")\n",
    "    if torch.isinf(tensor).any():\n",
    "        print(f\"{name} contains Inf values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "412681a5-dba6-438e-80ef-f7a621882394",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_nan_inf(obj.pos, \"sample 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5314ca7a-ceba-4283-bbb2-c5abfaa00ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred for obj i=0\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=1\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=2\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=3\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=4\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=5\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=6\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=7\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=8\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=9\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=10\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=11\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=12\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=13\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=14\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=15\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=16\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=17\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=18\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=19\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=20\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=21\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=22\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=23\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=24\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=25\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n",
      "pred for obj i=26\n",
      "CustomDataBatch(x=[20480, 1], y=[10], pos=[20480, 3], bbox_features=[10, 7], batch=[20480], ptr=[11])\n",
      "x after conv1 : torch.Size([20480, 10])\n",
      "Conv1 done\n",
      "x after conv2 : torch.Size([20480, 20])\n",
      "Conv2 done\n",
      "x after conv3 : torch.Size([20480, 30])\n",
      "Conv3 done\n",
      "x after max pool : torch.Size([10, 30])\n",
      "Max Pool done\n",
      "Forward 1 done\n",
      "x after concat : torch.Size([10, 50])\n",
      "Concatenate done\n",
      "Classification done\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "i = 0\n",
    "for data in train_loader:\n",
    "    print(f\"pred for obj i={i}\")\n",
    "    i += 1\n",
    "    print(data)\n",
    "    out = model(data)\n",
    "    outputs.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c9ac1-0f06-42d1-babb-117c8ac981f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
